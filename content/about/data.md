---
title: Data Security
---

# Data Security

While the connection to this site is encrypted, this is only the data in transit to you and to other servers in the federated network.
**The messages and data stored on our servers are not encrypted.** This is not a choice of the administrator, but a limitation of the Mastodon platform.

In addition to our processes, our hosting providers may have access to your data as part of the general administration of the server infrastructure, subject to their own Terms of Service.

## Private Mentions

Unless it's required of us to investigate a report of abuse of our policies, under standard operation our moderators have no ability to access your private mentions with other members of our Mastodon platform. Due in part to the open and federated nature of Mastodon servers, the Mastodon administrators of other servers you interact with may have access to your data and messages delivered to their servers.

Additionally, other non-Mastodon fediverse platforms may handle private messages differently and, either intentionally or unintentionally, expose those messages to unintended persons.

While our server administrators do have access to these messages through raw database access, this is not done except under the circumstances outlined above.
Where possible, we will notify you if such processes are taken for data associated with your account.

You should use [Signal](https://www.signal.org/), [Matrix](https://joinmatrix.org/), or another end-to-end encrypted messaging platform for communications that you want to be secured and visible only to you and the intended party.

## Large Language Models

A large language model, like ChatGPT, is a type of "artificial intelligence" program designed to understand and generate human-like text by processing vast amounts of written language.
While the creation and use of large language models are not inherently unethical or illegal, there are many important questions about how companies obtain their data to train their models and how that data is used.

vmst.io has taken some steps to limit organizations who build these models from accessing your public post data.
In some cases, this involves directly blocking the accessibility of third-parties to our site through firewalls, but in most cases, this is done by requesting that they not index our site through user agent flags in our [robots.txt](https://vmst.io/robots.txt) file.

## Privacy Policy

Please review our full [Privacy Policy](/about/tos) for more information.